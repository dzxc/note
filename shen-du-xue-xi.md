# 深度学习

## 前言
知识准备
    Python
    微积分
    线性代数
硬件软件准备

anaconda

公式一览
    逻辑回归 
    $$\hat y^{(i)}=\sigma(w^TX^{(i)}+b)$$


    激活函数()
$$\sigma(z^{(i)})= \frac{1}{1+e^{-z^{(i)}}}$$

    损失函数(loss function)
$$L(\hat y^{(i)}, y^{(i)})= -(y^{(i)}log(\hat y^{(i)})) + (1-y^{(i)})log(1-\hat y^{(i)})$$
    
    
    成本函数(cost function)
$$J(w,b) = \frac{1}{m}\sum_{i=1}^{m}L(\hat y^{(i)},y^{(i)})=-\frac{1}{m}\sum_{i=1}^{m}[y^{(i)}log(\hat y^{(i)})+(1-y^{(i)})log(1-\hat y^{(i)})]$$


    梯度下降函数
        
    
    
概念

### 数据输入与矩阵

矩阵：

非结构数据类
图片:
图片的逻辑结构：由一个个像素点构成一个矩形，图片有长和宽，如64x64的一个矩阵，每个像素由r（red）g(green)b(blue)三种颜色组成，每一种颜色就有一个矩阵，三种颜色就有三个矩阵，64x64*3矩阵
计算机中存储结构：在人的思维里有矩阵这种多维结构，但在计算机里只有一维线性结构方式存储数据。
神经网络训练结构：

音频：

结构数据类


## 神经网络入门

### 什么是神经网络

神经元与神经网络
人工神经网络

神经网络越简单智商就越低，神经网络越复杂智商就越高


训练深度神经网络就是深度学习

### 神经元与神经网络

### 人工神经网络

### 神经网络如何预测

通过一个简单的计算公式：$$z = f(wx+b)$$
w 表示权重
x 表示样本
b 表示偏置

这个公式与一般线性方程 $$ y = ax+b$$很类似，但是与一般线性方程不同的是，线性方程的所处理的未知数同一时刻只有一个，而神经网络处理的样本x是特征，同时包含着许多个样本，就需要用线性代数里面的矩阵方法来处理


神经网络通过学习已有的样本得到一组权重，再通过这组权重来判断给定的样本的匹配概览是多少

#### 逻辑回归

#### 激活函数引入
通过逻辑回归计算得出的结果不能直接作为预测结果，需要激活函数激活
##如何判断预测结果是否准确（ 损失函数引入）
计算预测结果与真实结果的差，就是损失函数
 
### 神经网络学习流程
输入数据
前向传播
反向传播
梯度下降


## 前向传播
### 逻辑回归
### 激活函数
### 损失函数
### 成本函数

## 反向传播

## 相关函数导数计算

## 梯度下降

## 激活函数
### sigmoid
### tanh
### relu
### leaky-relu




## 神经网络调优
### 神经网络缺陷
### 过拟合与欠拟合
### 梯度消失与梯度爆炸



## 神经网络实战